{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sem_x</th>\n",
       "      <th>codigo_x</th>\n",
       "      <th>dias_pag</th>\n",
       "      <th>dias_lab</th>\n",
       "      <th>sueldo</th>\n",
       "      <th>comp</th>\n",
       "      <th>asist</th>\n",
       "      <th>transp</th>\n",
       "      <th>vales_x</th>\n",
       "      <th>te_dob</th>\n",
       "      <th>...</th>\n",
       "      <th>alim</th>\n",
       "      <th>infon</th>\n",
       "      <th>falt</th>\n",
       "      <th>enf</th>\n",
       "      <th>ries</th>\n",
       "      <th>ISPT</th>\n",
       "      <th>ISPTA</th>\n",
       "      <th>IMSS</th>\n",
       "      <th>subs</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7840</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1143.52</td>\n",
       "      <td>462.91</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>257.02</td>\n",
       "      <td>367.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>289.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7505</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>721.00</td>\n",
       "      <td>173.04</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>143.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6600</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>721.00</td>\n",
       "      <td>30.38</td>\n",
       "      <td>60.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>120.22</td>\n",
       "      <td>180.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.07</td>\n",
       "      <td>33.13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>7685</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>721.00</td>\n",
       "      <td>30.38</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>120.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.04</td>\n",
       "      <td>38.26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7331</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>721.00</td>\n",
       "      <td>30.38</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>120.22</td>\n",
       "      <td>103.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.71</td>\n",
       "      <td>34.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sem_x  codigo_x  dias_pag  dias_lab   sueldo    comp  asist  transp  \\\n",
       "0      1      7840       7.0       5.0  1143.52  462.91   60.0    60.0   \n",
       "1      1      7505       7.0       5.0   721.00  173.04   60.0    60.0   \n",
       "2      1      6600       7.0       5.0   721.00   30.38   60.0    50.0   \n",
       "3      1      7685       7.0       5.0   721.00   30.38   60.0    60.0   \n",
       "4      1      7331       7.0       5.0   721.00   30.38   60.0    60.0   \n",
       "\n",
       "   vales_x  te_dob  ...  alim  infon  falt  enf  ries    ISPT  ISPTA   IMSS  \\\n",
       "0   257.02  367.56  ...   0.0    0.0   0.0  0.0   0.0  289.63    0.0  49.55   \n",
       "1   143.04    0.00  ...   0.0    0.0   0.0  0.0   0.0   60.93    0.0  24.12   \n",
       "2   120.22  180.25  ...   0.0    0.0   0.0  0.0   0.0    0.00    0.0  20.07   \n",
       "3   120.22    0.00  ...   0.0    0.0   0.0  0.0   0.0    0.00    0.0  27.04   \n",
       "4   120.22  103.00  ...   0.0    0.0   0.0  0.0   0.0    0.00    0.0  23.71   \n",
       "\n",
       "    subs  label  \n",
       "0   0.00      0  \n",
       "1   0.00      0  \n",
       "2  33.13      1  \n",
       "3  38.26      1  \n",
       "4  34.96      0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"./Resources/CONSOLIDADO.csv\", index_col=0)\n",
    "# Drop the null rows\n",
    "df = df.dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sem_x</th>\n",
       "      <th>codigo_x</th>\n",
       "      <th>dias_pag</th>\n",
       "      <th>dias_lab</th>\n",
       "      <th>sueldo</th>\n",
       "      <th>comp</th>\n",
       "      <th>asist</th>\n",
       "      <th>transp</th>\n",
       "      <th>vales_x</th>\n",
       "      <th>te_dob</th>\n",
       "      <th>...</th>\n",
       "      <th>alim</th>\n",
       "      <th>infon</th>\n",
       "      <th>falt</th>\n",
       "      <th>enf</th>\n",
       "      <th>ries</th>\n",
       "      <th>ISPT</th>\n",
       "      <th>ISPTA</th>\n",
       "      <th>IMSS</th>\n",
       "      <th>subs</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7840</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1143.52</td>\n",
       "      <td>462.91</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>257.02</td>\n",
       "      <td>367.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>289.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.55</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7505</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>721.00</td>\n",
       "      <td>173.04</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>143.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.12</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6600</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>721.00</td>\n",
       "      <td>30.38</td>\n",
       "      <td>60.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>120.22</td>\n",
       "      <td>180.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.07</td>\n",
       "      <td>33.13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>7685</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>721.00</td>\n",
       "      <td>30.38</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>120.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.04</td>\n",
       "      <td>38.26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7331</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>721.00</td>\n",
       "      <td>30.38</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>120.22</td>\n",
       "      <td>103.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.71</td>\n",
       "      <td>34.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sem_x  codigo_x  dias_pag  dias_lab   sueldo    comp  asist  transp  \\\n",
       "0      1      7840       7.0       5.0  1143.52  462.91   60.0    60.0   \n",
       "1      1      7505       7.0       5.0   721.00  173.04   60.0    60.0   \n",
       "2      1      6600       7.0       5.0   721.00   30.38   60.0    50.0   \n",
       "3      1      7685       7.0       5.0   721.00   30.38   60.0    60.0   \n",
       "4      1      7331       7.0       5.0   721.00   30.38   60.0    60.0   \n",
       "\n",
       "   vales_x  te_dob  ...  alim  infon  falt  enf  ries    ISPT  ISPTA   IMSS  \\\n",
       "0   257.02  367.56  ...   0.0    0.0   0.0  0.0   0.0  289.63    0.0  49.55   \n",
       "1   143.04    0.00  ...   0.0    0.0   0.0  0.0   0.0   60.93    0.0  24.12   \n",
       "2   120.22  180.25  ...   0.0    0.0   0.0  0.0   0.0    0.00    0.0  20.07   \n",
       "3   120.22    0.00  ...   0.0    0.0   0.0  0.0   0.0    0.00    0.0  27.04   \n",
       "4   120.22  103.00  ...   0.0    0.0   0.0  0.0   0.0    0.00    0.0  23.71   \n",
       "\n",
       "    subs  label  \n",
       "0   0.00      0  \n",
       "1   0.00      0  \n",
       "2  33.13      1  \n",
       "3  38.26      1  \n",
       "4  34.96      0  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropna(how='all', axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select your features (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8213"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set features. This will also be used as your x values.\n",
    "X = df[[\"dias_pag\",\"dias_lab\",\"sueldo\",\"comp\",\"asist\",\"transp\",\"vales_x\",\"te_dob\",\n",
    "          \"te_trip\",\"desc_Lab\",\"fest_lab\",\"dominic\",\"perc_grav\",\"obj\",\"aguin\",\"vac\",\"prim_vac\",\n",
    "          \"grat_esp\",\"util\",\"zapatos\",\"otras\",\"fonac\",\"alim\",\"infon\",\"falt\",\"enf\",\"ries\",\"ISPT\",\"IMSS\",\"subs\",\"label\"]]\n",
    "X.head()\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n",
    "\n",
    "Use `koi_disposition` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8213"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df['label']\n",
    "len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use train_test_split to create training and testing data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dias_pag</th>\n",
       "      <th>dias_lab</th>\n",
       "      <th>sueldo</th>\n",
       "      <th>comp</th>\n",
       "      <th>asist</th>\n",
       "      <th>transp</th>\n",
       "      <th>vales_x</th>\n",
       "      <th>te_dob</th>\n",
       "      <th>te_trip</th>\n",
       "      <th>desc_Lab</th>\n",
       "      <th>...</th>\n",
       "      <th>fonac</th>\n",
       "      <th>alim</th>\n",
       "      <th>infon</th>\n",
       "      <th>falt</th>\n",
       "      <th>enf</th>\n",
       "      <th>ries</th>\n",
       "      <th>ISPT</th>\n",
       "      <th>IMSS</th>\n",
       "      <th>subs</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7711</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>878.01</td>\n",
       "      <td>307.65</td>\n",
       "      <td>60.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>189.70</td>\n",
       "      <td>31.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>250.86</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65.59</td>\n",
       "      <td>37.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3826</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>721.00</td>\n",
       "      <td>123.06</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>135.04</td>\n",
       "      <td>180.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.27</td>\n",
       "      <td>29.84</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>721.00</td>\n",
       "      <td>123.06</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>135.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>201.35</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.95</td>\n",
       "      <td>32.33</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3214</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>721.00</td>\n",
       "      <td>30.38</td>\n",
       "      <td>60.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>120.22</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18.65</td>\n",
       "      <td>39.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024</th>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>721.00</td>\n",
       "      <td>102.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>112.86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>120.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.92</td>\n",
       "      <td>47.10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      dias_pag  dias_lab  sueldo    comp  asist  transp  vales_x  te_dob  \\\n",
       "7711       7.0       6.0  878.01  307.65   60.0    50.0   189.70   31.35   \n",
       "3826       7.0       6.0  721.00  123.06   60.0    60.0   135.04  180.25   \n",
       "746        7.0       6.0  721.00  123.06   60.0    60.0   135.04    0.00   \n",
       "3214       7.0       6.0  721.00   30.38   60.0    50.0   120.22    0.00   \n",
       "2024       7.0       5.0  721.00  102.84    0.0    50.0   112.86    0.00   \n",
       "\n",
       "      te_trip  desc_Lab  ...  fonac  alim   infon    falt  enf  ries   ISPT  \\\n",
       "7711      0.0    250.86  ...    0.0   0.0    0.00    0.00  0.0   0.0  65.59   \n",
       "3826      0.0      0.00  ...    0.0   0.0    0.00    0.00  0.0   0.0   4.27   \n",
       "746       0.0      0.00  ...    0.0   0.0  201.35    0.00  0.0   0.0   0.00   \n",
       "3214      0.0      0.00  ...    0.0   0.0    0.00    0.00  0.0   0.0   0.00   \n",
       "2024      0.0      0.00  ...    0.0   0.0    0.00  120.51  0.0   0.0   0.00   \n",
       "\n",
       "       IMSS   subs  label  \n",
       "7711  37.40   0.00      1  \n",
       "3826  29.84   0.00      1  \n",
       "746   20.95  32.33      0  \n",
       "3214  18.65  39.01      0  \n",
       "2024  20.92  47.10      1  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gonzalo\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\Gonzalo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n",
      "C:\\Users\\Gonzalo\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:9: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "# Scale your data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a StandardScater model and fit it to the training data\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "# Transform the training and testing data using the X_scaler\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train_scaled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_test_scaled[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# Step 1: Label-encode data set\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "encoded_y_train = label_encoder.transform(y_train)\n",
    "encoded_y_test = label_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Convert encoded labels to one-hot-encoding\n",
    "# ohe = \n",
    "#y_train_categorical = to_categorical(encoded_y_train)\n",
    "#y_test_categorical = to_categorical(encoded_y_test)\n",
    "\n",
    "#y_train_categorical = y_train_categorical[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a StandardScater model and fit it to the training data\n",
    "#y_train.reshape(-1, 1) \n",
    "#y_scaler = StandardScaler().fit(y_train)\n",
    "# Transform the training and testing data using the X_scaler\n",
    "\n",
    "#y_train_scaled = y_scaler.transform(y_train)\n",
    "#y_test_scaled = y_scaler.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model and add layers\n",
    "model = Sequential()\n",
    "model.add(Dense(units=40, activation='relu', input_dim=31))\n",
    "model.add(Dense(units=2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and fit the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_5 (Dense)              (None, 40)                1280      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 2)                 82        \n",
      "=================================================================\n",
      "Total params: 1,362\n",
      "Trainable params: 1,362\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "6159/6159 - 0s - loss: 0.2930 - acc: 0.9302\n",
      "Epoch 2/60\n",
      "6159/6159 - 0s - loss: 0.0459 - acc: 0.9984\n",
      "Epoch 3/60\n",
      "6159/6159 - 0s - loss: 0.0138 - acc: 0.9997\n",
      "Epoch 4/60\n",
      "6159/6159 - 0s - loss: 0.0065 - acc: 1.0000\n",
      "Epoch 5/60\n",
      "6159/6159 - 0s - loss: 0.0037 - acc: 1.0000\n",
      "Epoch 6/60\n",
      "6159/6159 - 0s - loss: 0.0024 - acc: 1.0000\n",
      "Epoch 7/60\n",
      "6159/6159 - 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 8/60\n",
      "6159/6159 - 0s - loss: 0.0012 - acc: 1.0000\n",
      "Epoch 9/60\n",
      "6159/6159 - 0s - loss: 8.8844e-04 - acc: 1.0000\n",
      "Epoch 10/60\n",
      "6159/6159 - 0s - loss: 6.8429e-04 - acc: 1.0000\n",
      "Epoch 11/60\n",
      "6159/6159 - 0s - loss: 5.3770e-04 - acc: 1.0000\n",
      "Epoch 12/60\n",
      "6159/6159 - 0s - loss: 4.3102e-04 - acc: 1.0000\n",
      "Epoch 13/60\n",
      "6159/6159 - 0s - loss: 3.5108e-04 - acc: 1.0000\n",
      "Epoch 14/60\n",
      "6159/6159 - 0s - loss: 2.8765e-04 - acc: 1.0000\n",
      "Epoch 15/60\n",
      "6159/6159 - 0s - loss: 2.3982e-04 - acc: 1.0000\n",
      "Epoch 16/60\n",
      "6159/6159 - 0s - loss: 2.0164e-04 - acc: 1.0000\n",
      "Epoch 17/60\n",
      "6159/6159 - 0s - loss: 1.7102e-04 - acc: 1.0000\n",
      "Epoch 18/60\n",
      "6159/6159 - 0s - loss: 1.4552e-04 - acc: 1.0000\n",
      "Epoch 19/60\n",
      "6159/6159 - 0s - loss: 1.2361e-04 - acc: 1.0000\n",
      "Epoch 20/60\n",
      "6159/6159 - 0s - loss: 1.0609e-04 - acc: 1.0000\n",
      "Epoch 21/60\n",
      "6159/6159 - 0s - loss: 9.1455e-05 - acc: 1.0000\n",
      "Epoch 22/60\n",
      "6159/6159 - 0s - loss: 7.9889e-05 - acc: 1.0000\n",
      "Epoch 23/60\n",
      "6159/6159 - 0s - loss: 6.9830e-05 - acc: 1.0000\n",
      "Epoch 24/60\n",
      "6159/6159 - 0s - loss: 6.0449e-05 - acc: 1.0000\n",
      "Epoch 25/60\n",
      "6159/6159 - 0s - loss: 5.3341e-05 - acc: 1.0000\n",
      "Epoch 26/60\n",
      "6159/6159 - 0s - loss: 4.7034e-05 - acc: 1.0000\n",
      "Epoch 27/60\n",
      "6159/6159 - 0s - loss: 4.1309e-05 - acc: 1.0000\n",
      "Epoch 28/60\n",
      "6159/6159 - 0s - loss: 3.6853e-05 - acc: 1.0000\n",
      "Epoch 29/60\n",
      "6159/6159 - 0s - loss: 3.2355e-05 - acc: 1.0000\n",
      "Epoch 30/60\n",
      "6159/6159 - 0s - loss: 2.8900e-05 - acc: 1.0000\n",
      "Epoch 31/60\n",
      "6159/6159 - 0s - loss: 2.5735e-05 - acc: 1.0000\n",
      "Epoch 32/60\n",
      "6159/6159 - 0s - loss: 2.2935e-05 - acc: 1.0000\n",
      "Epoch 33/60\n",
      "6159/6159 - 0s - loss: 2.0388e-05 - acc: 1.0000\n",
      "Epoch 34/60\n",
      "6159/6159 - 0s - loss: 1.8001e-05 - acc: 1.0000\n",
      "Epoch 35/60\n",
      "6159/6159 - 0s - loss: 1.5984e-05 - acc: 1.0000\n",
      "Epoch 36/60\n",
      "6159/6159 - 0s - loss: 1.4344e-05 - acc: 1.0000\n",
      "Epoch 37/60\n",
      "6159/6159 - 0s - loss: 1.2739e-05 - acc: 1.0000\n",
      "Epoch 38/60\n",
      "6159/6159 - 0s - loss: 1.1439e-05 - acc: 1.0000\n",
      "Epoch 39/60\n",
      "6159/6159 - 0s - loss: 1.0165e-05 - acc: 1.0000\n",
      "Epoch 40/60\n",
      "6159/6159 - 0s - loss: 9.0982e-06 - acc: 1.0000\n",
      "Epoch 41/60\n",
      "6159/6159 - 0s - loss: 8.1913e-06 - acc: 1.0000\n",
      "Epoch 42/60\n",
      "6159/6159 - 0s - loss: 7.2331e-06 - acc: 1.0000\n",
      "Epoch 43/60\n",
      "6159/6159 - 0s - loss: 6.5162e-06 - acc: 1.0000\n",
      "Epoch 44/60\n",
      "6159/6159 - 0s - loss: 5.8595e-06 - acc: 1.0000\n",
      "Epoch 45/60\n",
      "6159/6159 - 0s - loss: 5.2374e-06 - acc: 1.0000\n",
      "Epoch 46/60\n",
      "6159/6159 - 0s - loss: 4.7056e-06 - acc: 1.0000\n",
      "Epoch 47/60\n",
      "6159/6159 - 0s - loss: 4.1937e-06 - acc: 1.0000\n",
      "Epoch 48/60\n",
      "6159/6159 - 0s - loss: 3.7506e-06 - acc: 1.0000\n",
      "Epoch 49/60\n",
      "6159/6159 - 0s - loss: 3.3379e-06 - acc: 1.0000\n",
      "Epoch 50/60\n",
      "6159/6159 - 0s - loss: 3.0258e-06 - acc: 1.0000\n",
      "Epoch 51/60\n",
      "6159/6159 - 0s - loss: 2.6548e-06 - acc: 1.0000\n",
      "Epoch 52/60\n",
      "6159/6159 - 0s - loss: 2.3893e-06 - acc: 1.0000\n",
      "Epoch 53/60\n",
      "6159/6159 - 0s - loss: 2.1627e-06 - acc: 1.0000\n",
      "Epoch 54/60\n",
      "6159/6159 - 0s - loss: 1.9014e-06 - acc: 1.0000\n",
      "Epoch 55/60\n",
      "6159/6159 - 0s - loss: 1.7179e-06 - acc: 1.0000\n",
      "Epoch 56/60\n",
      "6159/6159 - 0s - loss: 1.5460e-06 - acc: 1.0000\n",
      "Epoch 57/60\n",
      "6159/6159 - 0s - loss: 1.3847e-06 - acc: 1.0000\n",
      "Epoch 58/60\n",
      "6159/6159 - 0s - loss: 1.2602e-06 - acc: 1.0000\n",
      "Epoch 59/60\n",
      "6159/6159 - 0s - loss: 1.1059e-06 - acc: 1.0000\n",
      "Epoch 60/60\n",
      "6159/6159 - 0s - loss: 9.9121e-07 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22fa2641e10>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train_scaled,\n",
    "    y_train,\n",
    "    epochs=60,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Quantify our Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6159/6159 - 0s - loss: 9.2642e-07 - acc: 1.0000\n",
      "Train Neural Network - Loss: 9.26424386847659e-07, Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = model.evaluate(\n",
    "    X_train_scaled, y_train, verbose=2)\n",
    "print(\n",
    "    f\"Train Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 50)                1600      \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 4,252\n",
      "Trainable params: 4,252\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "deep_model = Sequential()\n",
    "deep_model.add(Dense(units=50, activation='relu', input_dim=31))\n",
    "deep_model.add(Dense(units=50, activation='relu'))\n",
    "deep_model.add(Dense(units=2, activation='softmax'))\n",
    "deep_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2054/2054 - 0s - loss: 0.3854 - acc: 0.8681\n",
      "Epoch 2/100\n",
      "2054/2054 - 0s - loss: 0.0642 - acc: 0.9956\n",
      "Epoch 3/100\n",
      "2054/2054 - 0s - loss: 0.0119 - acc: 0.9995\n",
      "Epoch 4/100\n",
      "2054/2054 - 0s - loss: 0.0047 - acc: 1.0000\n",
      "Epoch 5/100\n",
      "2054/2054 - 0s - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 6/100\n",
      "2054/2054 - 0s - loss: 0.0016 - acc: 1.0000\n",
      "Epoch 7/100\n",
      "2054/2054 - 0s - loss: 0.0011 - acc: 1.0000\n",
      "Epoch 8/100\n",
      "2054/2054 - 0s - loss: 8.1022e-04 - acc: 1.0000\n",
      "Epoch 9/100\n",
      "2054/2054 - 0s - loss: 6.1871e-04 - acc: 1.0000\n",
      "Epoch 10/100\n",
      "2054/2054 - 0s - loss: 4.8980e-04 - acc: 1.0000\n",
      "Epoch 11/100\n",
      "2054/2054 - 0s - loss: 3.9775e-04 - acc: 1.0000\n",
      "Epoch 12/100\n",
      "2054/2054 - 0s - loss: 3.2950e-04 - acc: 1.0000\n",
      "Epoch 13/100\n",
      "2054/2054 - 0s - loss: 2.7734e-04 - acc: 1.0000\n",
      "Epoch 14/100\n",
      "2054/2054 - 0s - loss: 2.3640e-04 - acc: 1.0000\n",
      "Epoch 15/100\n",
      "2054/2054 - 0s - loss: 2.0303e-04 - acc: 1.0000\n",
      "Epoch 16/100\n",
      "2054/2054 - 0s - loss: 1.7660e-04 - acc: 1.0000\n",
      "Epoch 17/100\n",
      "2054/2054 - 0s - loss: 1.5438e-04 - acc: 1.0000\n",
      "Epoch 18/100\n",
      "2054/2054 - 0s - loss: 1.3637e-04 - acc: 1.0000\n",
      "Epoch 19/100\n",
      "2054/2054 - 0s - loss: 1.2061e-04 - acc: 1.0000\n",
      "Epoch 20/100\n",
      "2054/2054 - 0s - loss: 1.0804e-04 - acc: 1.0000\n",
      "Epoch 21/100\n",
      "2054/2054 - 0s - loss: 9.7296e-05 - acc: 1.0000\n",
      "Epoch 22/100\n",
      "2054/2054 - 0s - loss: 8.7769e-05 - acc: 1.0000\n",
      "Epoch 23/100\n",
      "2054/2054 - 0s - loss: 7.9366e-05 - acc: 1.0000\n",
      "Epoch 24/100\n",
      "2054/2054 - 0s - loss: 7.2240e-05 - acc: 1.0000\n",
      "Epoch 25/100\n",
      "2054/2054 - 0s - loss: 6.5912e-05 - acc: 1.0000\n",
      "Epoch 26/100\n",
      "2054/2054 - 0s - loss: 6.0494e-05 - acc: 1.0000\n",
      "Epoch 27/100\n",
      "2054/2054 - 0s - loss: 5.5710e-05 - acc: 1.0000\n",
      "Epoch 28/100\n",
      "2054/2054 - 0s - loss: 5.1321e-05 - acc: 1.0000\n",
      "Epoch 29/100\n",
      "2054/2054 - 0s - loss: 4.7416e-05 - acc: 1.0000\n",
      "Epoch 30/100\n",
      "2054/2054 - 0s - loss: 4.3908e-05 - acc: 1.0000\n",
      "Epoch 31/100\n",
      "2054/2054 - 0s - loss: 4.0824e-05 - acc: 1.0000\n",
      "Epoch 32/100\n",
      "2054/2054 - 0s - loss: 3.7930e-05 - acc: 1.0000\n",
      "Epoch 33/100\n",
      "2054/2054 - 0s - loss: 3.5354e-05 - acc: 1.0000\n",
      "Epoch 34/100\n",
      "2054/2054 - 0s - loss: 3.2931e-05 - acc: 1.0000\n",
      "Epoch 35/100\n",
      "2054/2054 - 0s - loss: 3.0816e-05 - acc: 1.0000\n",
      "Epoch 36/100\n",
      "2054/2054 - 0s - loss: 2.8808e-05 - acc: 1.0000\n",
      "Epoch 37/100\n",
      "2054/2054 - 0s - loss: 2.6992e-05 - acc: 1.0000\n",
      "Epoch 38/100\n",
      "2054/2054 - 0s - loss: 2.5310e-05 - acc: 1.0000\n",
      "Epoch 39/100\n",
      "2054/2054 - 0s - loss: 2.4211e-05 - acc: 1.0000\n",
      "Epoch 40/100\n",
      "2054/2054 - 0s - loss: 2.2265e-05 - acc: 1.0000\n",
      "Epoch 41/100\n",
      "2054/2054 - 0s - loss: 2.0888e-05 - acc: 1.0000\n",
      "Epoch 42/100\n",
      "2054/2054 - 0s - loss: 1.9699e-05 - acc: 1.0000\n",
      "Epoch 43/100\n",
      "2054/2054 - 0s - loss: 1.8630e-05 - acc: 1.0000\n",
      "Epoch 44/100\n",
      "2054/2054 - 0s - loss: 1.7583e-05 - acc: 1.0000\n",
      "Epoch 45/100\n",
      "2054/2054 - 0s - loss: 1.6619e-05 - acc: 1.0000\n",
      "Epoch 46/100\n",
      "2054/2054 - 0s - loss: 1.5735e-05 - acc: 1.0000\n",
      "Epoch 47/100\n",
      "2054/2054 - 0s - loss: 1.4876e-05 - acc: 1.0000\n",
      "Epoch 48/100\n",
      "2054/2054 - 0s - loss: 1.4107e-05 - acc: 1.0000\n",
      "Epoch 49/100\n",
      "2054/2054 - 0s - loss: 1.3358e-05 - acc: 1.0000\n",
      "Epoch 50/100\n",
      "2054/2054 - 0s - loss: 1.2666e-05 - acc: 1.0000\n",
      "Epoch 51/100\n",
      "2054/2054 - 0s - loss: 1.2054e-05 - acc: 1.0000\n",
      "Epoch 52/100\n",
      "2054/2054 - 0s - loss: 1.1433e-05 - acc: 1.0000\n",
      "Epoch 53/100\n",
      "2054/2054 - 0s - loss: 1.0868e-05 - acc: 1.0000\n",
      "Epoch 54/100\n",
      "2054/2054 - 0s - loss: 1.0328e-05 - acc: 1.0000\n",
      "Epoch 55/100\n",
      "2054/2054 - 0s - loss: 9.8326e-06 - acc: 1.0000\n",
      "Epoch 56/100\n",
      "2054/2054 - 0s - loss: 9.3425e-06 - acc: 1.0000\n",
      "Epoch 57/100\n",
      "2054/2054 - 0s - loss: 8.8928e-06 - acc: 1.0000\n",
      "Epoch 58/100\n",
      "2054/2054 - 0s - loss: 8.4921e-06 - acc: 1.0000\n",
      "Epoch 59/100\n",
      "2054/2054 - 0s - loss: 8.0687e-06 - acc: 1.0000\n",
      "Epoch 60/100\n",
      "2054/2054 - 0s - loss: 7.6900e-06 - acc: 1.0000\n",
      "Epoch 61/100\n",
      "2054/2054 - 0s - loss: 7.3411e-06 - acc: 1.0000\n",
      "Epoch 62/100\n",
      "2054/2054 - 0s - loss: 7.0321e-06 - acc: 1.0000\n",
      "Epoch 63/100\n",
      "2054/2054 - 0s - loss: 6.7072e-06 - acc: 1.0000\n",
      "Epoch 64/100\n",
      "2054/2054 - 0s - loss: 6.3790e-06 - acc: 1.0000\n",
      "Epoch 65/100\n",
      "2054/2054 - 0s - loss: 6.1157e-06 - acc: 1.0000\n",
      "Epoch 66/100\n",
      "2054/2054 - 0s - loss: 5.8373e-06 - acc: 1.0000\n",
      "Epoch 67/100\n",
      "2054/2054 - 0s - loss: 5.5898e-06 - acc: 1.0000\n",
      "Epoch 68/100\n",
      "2054/2054 - 0s - loss: 5.3325e-06 - acc: 1.0000\n",
      "Epoch 69/100\n",
      "2054/2054 - 0s - loss: 5.1007e-06 - acc: 1.0000\n",
      "Epoch 70/100\n",
      "2054/2054 - 0s - loss: 4.8698e-06 - acc: 1.0000\n",
      "Epoch 71/100\n",
      "2054/2054 - 0s - loss: 4.6551e-06 - acc: 1.0000\n",
      "Epoch 72/100\n",
      "2054/2054 - 0s - loss: 4.4519e-06 - acc: 1.0000\n",
      "Epoch 73/100\n",
      "2054/2054 - 0s - loss: 4.2634e-06 - acc: 1.0000\n",
      "Epoch 74/100\n",
      "2054/2054 - 0s - loss: 4.0753e-06 - acc: 1.0000\n",
      "Epoch 75/100\n",
      "2054/2054 - 0s - loss: 3.9028e-06 - acc: 1.0000\n",
      "Epoch 76/100\n",
      "2054/2054 - 0s - loss: 3.7327e-06 - acc: 1.0000\n",
      "Epoch 77/100\n",
      "2054/2054 - 0s - loss: 3.5746e-06 - acc: 1.0000\n",
      "Epoch 78/100\n",
      "2054/2054 - 0s - loss: 3.4279e-06 - acc: 1.0000\n",
      "Epoch 79/100\n",
      "2054/2054 - 0s - loss: 3.2838e-06 - acc: 1.0000\n",
      "Epoch 80/100\n",
      "2054/2054 - 0s - loss: 3.1455e-06 - acc: 1.0000\n",
      "Epoch 81/100\n",
      "2054/2054 - 0s - loss: 3.0166e-06 - acc: 1.0000\n",
      "Epoch 82/100\n",
      "2054/2054 - 0s - loss: 2.8943e-06 - acc: 1.0000\n",
      "Epoch 83/100\n",
      "2054/2054 - 0s - loss: 2.7736e-06 - acc: 1.0000\n",
      "Epoch 84/100\n",
      "2054/2054 - 0s - loss: 2.6633e-06 - acc: 1.0000\n",
      "Epoch 85/100\n",
      "2054/2054 - 0s - loss: 2.5525e-06 - acc: 1.0000\n",
      "Epoch 86/100\n",
      "2054/2054 - 0s - loss: 2.4422e-06 - acc: 1.0000\n",
      "Epoch 87/100\n",
      "2054/2054 - 0s - loss: 2.3455e-06 - acc: 1.0000\n",
      "Epoch 88/100\n",
      "2054/2054 - 0s - loss: 2.2510e-06 - acc: 1.0000\n",
      "Epoch 89/100\n",
      "2054/2054 - 0s - loss: 2.1622e-06 - acc: 1.0000\n",
      "Epoch 90/100\n",
      "2054/2054 - 0s - loss: 2.0757e-06 - acc: 1.0000\n",
      "Epoch 91/100\n",
      "2054/2054 - 0s - loss: 1.9998e-06 - acc: 1.0000\n",
      "Epoch 92/100\n",
      "2054/2054 - 0s - loss: 1.9186e-06 - acc: 1.0000\n",
      "Epoch 93/100\n",
      "2054/2054 - 0s - loss: 1.8399e-06 - acc: 1.0000\n",
      "Epoch 94/100\n",
      "2054/2054 - 0s - loss: 1.7707e-06 - acc: 1.0000\n",
      "Epoch 95/100\n",
      "2054/2054 - 0s - loss: 1.6990e-06 - acc: 1.0000\n",
      "Epoch 96/100\n",
      "2054/2054 - 0s - loss: 1.6351e-06 - acc: 1.0000\n",
      "Epoch 97/100\n",
      "2054/2054 - 0s - loss: 1.5754e-06 - acc: 1.0000\n",
      "Epoch 98/100\n",
      "2054/2054 - 0s - loss: 1.5153e-06 - acc: 1.0000\n",
      "Epoch 99/100\n",
      "2054/2054 - 0s - loss: 1.4540e-06 - acc: 1.0000\n",
      "Epoch 100/100\n",
      "2054/2054 - 0s - loss: 1.3984e-06 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22fa3950eb8>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deep_model.compile(optimizer='adam',\n",
    "                   loss='sparse_categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "deep_model.fit(\n",
    "    X_test_scaled,\n",
    "    y_test,\n",
    "    epochs=100,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2054/2054 - 0s - loss: 1.4904e-06 - acc: 1.0000\n",
      "Test Neural Network - Loss: 1.4903962052853595e-06, Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_accuracy = deep_model.evaluate(\n",
    "    X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Test Neural Network - Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
    "#print(f\"Training Data Score: {model.score(X_train_scaled, y_train)}\")\n",
    "#print(f\"Testing Data Score: {model.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearch estimator along with a parameter object containing the values to adjust\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "# Function to create model, required for KerasClassifier\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=100, activation='relu', input_dim=))\n",
    "    model.add(Dense(units=100, activation='relu'))\n",
    "    model.add(Dense(units=3, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "# create model\n",
    "model = KerasClassifier(build_fn=create_model, verbose=2)\n",
    "# define the grid search parameters\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X_train_scaled, y_train_categorical)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid.best_params_)\n",
    "print(grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-run deep_model with hypertuned paramters for neural network model:\n",
    "deep_model.compile(optimizer='adam',\n",
    "                   loss='categorical_crossentropy',\n",
    "                   metrics=['accuracy'])\n",
    "\n",
    "deep_model.fit(\n",
    "    X_test_scaled,\n",
    "    y_test_categorical,\n",
    "    epochs=10,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"RESULTS COMPARISSON:\")\n",
    "print(\"First trained/test deep_model: Accuracy= 0.914  Loss = 0.246\")\n",
    "print(\"Same deep_model/data with With tuned parameters: Accuracy = 0.988 Loss = 0.0598\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your model by updating \"your_name\" with your name\n",
    "# and \"your_model\" with your model variable\n",
    "# be sure to turn this in to BCS\n",
    "# if joblib fails to import, try running the command to install in terminal/git-bash\n",
    "import joblib\n",
    "filename = 'GCA_final_with35.sav'\n",
    "#joblib.dump(model1, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
